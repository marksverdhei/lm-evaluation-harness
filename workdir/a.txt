LOGLEVEL=DEBUG lm_eval \
  --model local-chat-completions \
  --tasks nortruthfulqa_gen_nob_p5 \
  --model_args base_url=http://localhost:8000/v1/chat/completions,num_concurrent=1,max_retries=999,tokenized_requests=True,model="GPTOSS-20B",tokenizer="openai/gpt-oss-20b" \
  --apply_chat_template \
  --gen_kwargs temperature=0.7,max_tokens=5000,max_completion_tokens=4096


lm_eval \
  --model local-chat-completions \
  --tasks nortruthfulqa_gen_nob_p5 \
  --model_args base_url=http://localhost:8000/v1/chat/completions,num_concurrent=1,max_retries=999,tokenized_requests=False,model="Q3-Thinking" \
  --apply_chat_template \
  --gen_kwargs temperature=0.6,top_k=20,top_p=0.95,max_tokens=5000,max_completion_tokens=4096


lm_eval \
  --model local-chat-completions \
  --tasks nortruthfulqa_gen_nob_p5 \
  --model_args base_url=http://localhost:8000/v1/chat/completions,num_concurrent=1,max_retries=999,tokenized_requests=False,model="Q3-Big" \
  --apply_chat_template \
  --gen_kwargs temperature=0.6,top_k=20,top_p=0.95,max_tokens=5000,max_completion_tokens=4096 \
  --output_path ./results/Q3-Big \
  --log_samples
